fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
w <- as.numeric(residuals(fit.treat))^2
sum((sort(w, decreasing = TRUE)[1:round(.11*(length(w)))]))/sum(w)
ate <- c()
df_copy <- df
for (i in 1:1000) {
df_copy$log_tweets_immigration <- sample(df$log_tweets_immigration, replace = FALSE)
eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df_copy))[2]
ate <- c(ate, eff)
}
real_eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df))[2]
sum(real_eff < ate)/1000
sink("midterm_output.tex")
lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
df <- df %>% mutate(binary_tweets = ifelse(log_tweets_immigration >= median(
log_tweets_immigration), 1, 0))
plot((MatchIt::matchit(binary_tweets ~ woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = na.omit(df))), type = "density")
# each observation in the full regression defined in the code on line 9. What % of the
# total weight is contributed by the top 10% of the observations?
fit.treat <- lm(log_tweets_immigration ~
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
fit.full <- lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
w <- as.numeric(residuals(fit.treat))^2
sum((sort(w, decreasing = TRUE)[1:round(.11*(length(w)))]))/sum(w)
## Randomization inference question
ate <- c()
df_copy <- df
for (i in 1:1000) {
df_copy$log_tweets_immigration <- sample(df$log_tweets_immigration, replace = FALSE)
eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df_copy))[2]
ate <- c(ate, eff)
}
real_eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df))[2]
sum(real_eff < ate)/1000
sink(file = NULL)
library(tidyverse)
library(fixest)
library(haven)
setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/code")
df <- haven::read_dta("angrist_krueger.dta")
df <- haven::read_dta("angrist_krueger.dta")
library(haven) # Read .dta files
library(data.table) # For working with data
library(fixest) # For regressions
library(binsreg) # For binscatter
library(ggplot2)
install.packages("binsreg")
library(binsreg) # For binscatter
data[, qob_1 := (qob == 1)]
data <- as.data.table(data)
## Load data
# data <- haven::read_dta("https://github.com/Mixtape-Sessions/Instrumental-Variables/blob/main/Exercises/Exercise1/angrist_krueger_91.dta?raw=true")
data <- read_dta("~/Downloads/angrist_krueger_91.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
(5.157450 - 5.148471)/(11.52515 - 11.39960)
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
# collapse data by qob
collapsed <- data[,
.(lwage = mean(lwage), educ = mean(educ)),
by = qob
]
# plot means
plot(collapsed$educ, collapsed$lwage)
# add regression line
abline(feols(lwage ~ educ, collapsed))
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
feols(
lwage ~ 1 | yob | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob_1) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
df <- haven::read_dta("hansen_dwi.dta")
library(haven) # Read .dta files
library(data.table) # For working with data
library(fixest) # For regressions
library(binsreg) # For binscatter
library(ggplot2)
setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/code/")
df <- haven::read_dta("angrist_krueger.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
df <- haven::read_dta("angrist_krueger.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
View(data)
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
(5.157450 - 5.148471) / (11.52515 - 11.39960 )
# collapse data by qob
collapsed <- data[,
.(lwage = mean(lwage), educ = mean(educ)),
by = qob
]
# plot means
plot(collapsed$educ, collapsed$lwage)
# add regression line
abline(feols(lwage ~ educ, collapsed))
feols(
lwage ~ 1 | yob | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob_1) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
df <- haven::read_dta("hansen_dwi.dta")
library(tidyverse)
library(fixest)
```{r load-exp-data}
library(DRDID) # devtools::install_github("pedrohcgs/DRDID")
install.packages("DRDID")
library(DRDID) # devtools::install_github("pedrohcgs/DRDID")
library(haven)
# 1. Experimental data
df_exp <- haven::read_dta("https://raw.github.com/Mixtape-Sessions/Causal-Inference-2/master/Lab/Lalonde/lalonde_exp_panel.dta")
# ---- Difference-in-means - Averages
with(df_exp, {
y11 = mean(re[year == 78 & ever_treated == 1])
y01 = mean(re[year == 78 & ever_treated == 0])
dim = y11 - y01
dim
})
# ---- Difference-in-means - OLS
feols(
re ~ i(treat),
data = df_exp |> filter(year == 78), vcov = "hc1"
)
# ---- Difference-in-Differences - Averages
with(df_exp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 78 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 78 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) | id + year,
data = df_exp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
# ---- Event study and pre-trends using manually calculated averages
with(df_exp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 74 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 74 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Event study and pre-trends using OLS
df_exp$pre = df_exp$ever_treated * (df_exp$year == 74)
df_exp$post = df_exp$ever_treated * (df_exp$year == 78)
feols(
re ~ i(post) + i(pre) | id + year,
data = df_exp,
vcov = "hc1"
)
# 2. CPS data
df_nonexp <- haven::read_dta("https://raw.github.com/Mixtape-Sessions/Causal-Inference-2/master/Lab/Lalonde/lalonde_nonexp_panel.dta")
# ---- Difference-in-means - Averages
with(df_nonexp, {
mean(re[year == 78 & ever_treated == 1]) -
mean(re[year == 78 & ever_treated == 0])
})
# ---- Difference-in-means - OLS
feols(
re ~ i(treat),
data = df_exp |> filter(year == 78), vcov = "hc1"
)
# ---- Difference-in-Differences - Averages
with(df_nonexp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 78 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 78 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) | id + year,
data = df_nonexp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
# ---- Event study and pre-trends using manually calculated averages
with(df_nonexp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 74 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 74 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Event study and pre-trends using OLS
df_nonexp$pre = df_nonexp$ever_treated * (df_nonexp$year == 74)
df_nonexp$post = df_nonexp$ever_treated * (df_nonexp$year == 78)
feols(
re ~ i(post) + i(pre) | id + year,
data = df_nonexp,
vcov = "hc1"
)
# ---- Difference-in-differeces - OLS with covariates
# age, agesq, agecube, educ, educsq, marr, nodegree, black, hisp
feols(re ~ i(post) + age + agesq + agecube + educ + educsq +
marr + nodegree + black + hisp | ever_treated + year,
data = df_nonexp,
vcov = "hc1"
)
# ---- Double-robust DID
DRDID::drdid(
yname = "re", tname = "year", idname = "id", dname = "ever_treated",
xformla = ~ age + agesq + agecube + educ + educsq +
marr + nodegree + black + hisp + re74 + u74,
data = df_nonexp |> filter(year == 75 | year == 78)
)
library(tidyverse)
library(fixest)
library(DRDID) # devtools::install_github("pedrohcgs/DRDID")
library(haven)
# 1. Experimental data
df_exp <- haven::read_dta("https://raw.github.com/Mixtape-Sessions/Causal-Inference-2/master/Lab/Lalonde/lalonde_exp_panel.dta")
# ---- Difference-in-means - Averages
with(df_exp, {
y11 = mean(re[year == 78 & ever_treated == 1])
y01 = mean(re[year == 78 & ever_treated == 0])
dim = y11 - y01
dim
})
# ---- Difference-in-means - OLS
feols(
re ~ i(treat),
data = df_exp |> filter(year == 78), vcov = "hc1"
)
with(df_exp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 78 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 78 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) | id + year,
data = df_exp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) |  year,
data = df_exp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
?feols
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) |  id + year,
data = df_exp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
# ---- Event study and pre-trends using manually calculated averages
with(df_exp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 74 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 74 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Event study and pre-trends using OLS
df_exp$pre = df_exp$ever_treated * (df_exp$year == 74)
# ---- Event study and pre-trends using OLS
df_exp$pre = df_exp$ever_treated * (df_exp$year == 74)
df_exp$post = df_exp$ever_treated * (df_exp$year == 78)
feols(
re ~ i(post) + i(pre) | id + year,
data = df_exp,
vcov = "hc1"
)
# 2. CPS data
df_nonexp <- haven::read_dta("https://raw.github.com/Mixtape-Sessions/Causal-Inference-2/master/Lab/Lalonde/lalonde_nonexp_panel.dta")
with(df_nonexp, {
mean(re[year == 78 & ever_treated == 1]) -
mean(re[year == 78 & ever_treated == 0])
})
# ---- Difference-in-means - OLS
feols(
re ~ i(treat),
data = df_exp |> filter(year == 78), vcov = "hc1"
)
# ---- Difference-in-means - OLS
feols(
re ~ i(treat),
data = df_nonexp |> filter(year == 78), vcov = "hc1"
)
# ---- Difference-in-Differences - Averages
with(df_nonexp, {
y00 = mean(re[year == 75 & ever_treated == 0])
y01 = mean(re[year == 78 & ever_treated == 0])
y10 = mean(re[year == 75 & ever_treated == 1])
y11 = mean(re[year == 78 & ever_treated == 1])
did = (y11 - y10) - (y01 - y00)
did
})
# ---- Difference-in-Differences - OLS
feols(
re ~ i(treat) | id + year,
data = df_nonexp |> filter(year %in% c(75, 78)),
vcov = "hc1"
)
# ---- Difference-in-differeces - OLS with covariates
# age, agesq, agecube, educ, educsq, marr, nodegree, black, hisp
feols(re ~ i(post) + age + agesq + agecube + educ + educsq +
marr + nodegree + black + hisp | ever_treated + year,
data = df_nonexp,
vcov = "hc1"
)
# ---- Event study and pre-trends using OLS
df_nonexp$pre = df_nonexp$ever_treated * (df_nonexp$year == 74)
df_nonexp$post = df_nonexp$ever_treated * (df_nonexp$year == 78)
# ---- Difference-in-differeces - OLS with covariates
# age, agesq, agecube, educ, educsq, marr, nodegree, black, hisp
feols(re ~ i(post) + age + agesq + agecube + educ + educsq +
marr + nodegree + black + hisp | ever_treated + year,
data = df_nonexp,
vcov = "hc1"
)
# ---- Double-robust DID
DRDID::drdid(
yname = "re", tname = "year", idname = "id", dname = "ever_treated",
xformla = ~ age + agesq + agecube + educ + educsq +
marr + nodegree + black + hisp + re74 + u74,
data = df_nonexp |> filter(year == 75 | year == 78)
)
