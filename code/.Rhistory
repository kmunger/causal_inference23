setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/midterm")
load("data_midterm.RData")
library(tidyverse)
lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
df <- df %>% mutate(binary_tweets = ifelse(log_tweets_immigration >= median(
log_tweets_immigration), 1, 0))
plot((MatchIt::matchit(binary_tweets ~ woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = na.omit(df))), type = "density")
fit.treat <- lm(log_tweets_immigration ~
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
fit.full <- lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
w <- as.numeric(residuals(fit.treat))^2
sum((sort(w, decreasing = TRUE)[1:round(.11*(length(w)))]))/sum(w)
ate <- c()
df_copy <- df
for (i in 1:1000) {
df_copy$log_tweets_immigration <- sample(df$log_tweets_immigration, replace = FALSE)
eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df_copy))[2]
ate <- c(ate, eff)
}
real_eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df))[2]
sum(real_eff < ate)/1000
sink("midterm_output.tex")
lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
df <- df %>% mutate(binary_tweets = ifelse(log_tweets_immigration >= median(
log_tweets_immigration), 1, 0))
plot((MatchIt::matchit(binary_tweets ~ woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = na.omit(df))), type = "density")
# each observation in the full regression defined in the code on line 9. What % of the
# total weight is contributed by the top 10% of the observations?
fit.treat <- lm(log_tweets_immigration ~
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
fit.full <- lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df)
w <- as.numeric(residuals(fit.treat))^2
sum((sort(w, decreasing = TRUE)[1:round(.11*(length(w)))]))/sum(w)
## Randomization inference question
ate <- c()
df_copy <- df
for (i in 1:1000) {
df_copy$log_tweets_immigration <- sample(df$log_tweets_immigration, replace = FALSE)
eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df_copy))[2]
ate <- c(ate, eff)
}
real_eff <- coef(lm(fact_immigrants_w3_correct_dk0 ~ log_tweets_immigration +
fact_immigrants_w2_correct_dk0 +
woman+ age+ lowerclass+ profile_education_age+
white_british+ married+ newsnight_freq+ religious+
internet_freq_inc+newspaper_type, data = df))[2]
sum(real_eff < ate)/1000
sink(file = NULL)
library(tidyverse)
library(fixest)
library(haven)
setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/code")
df <- haven::read_dta("angrist_krueger.dta")
df <- haven::read_dta("angrist_krueger.dta")
library(haven) # Read .dta files
library(data.table) # For working with data
library(fixest) # For regressions
library(binsreg) # For binscatter
library(ggplot2)
install.packages("binsreg")
library(binsreg) # For binscatter
data[, qob_1 := (qob == 1)]
data <- as.data.table(data)
## Load data
# data <- haven::read_dta("https://github.com/Mixtape-Sessions/Instrumental-Variables/blob/main/Exercises/Exercise1/angrist_krueger_91.dta?raw=true")
data <- read_dta("~/Downloads/angrist_krueger_91.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
(5.157450 - 5.148471)/(11.52515 - 11.39960)
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
# collapse data by qob
collapsed <- data[,
.(lwage = mean(lwage), educ = mean(educ)),
by = qob
]
# plot means
plot(collapsed$educ, collapsed$lwage)
# add regression line
abline(feols(lwage ~ educ, collapsed))
feols(
lwage ~ 1 | 0 | educ ~ qob_1 + qob_2 + qob_3,
data,
vcov = "hc1"
)
feols(
lwage ~ 1 | yob | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob_1) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
df <- haven::read_dta("hansen_dwi.dta")
library(haven) # Read .dta files
library(data.table) # For working with data
library(fixest) # For regressions
library(binsreg) # For binscatter
library(ggplot2)
setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/code/")
df <- haven::read_dta("angrist_krueger.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
df <- haven::read_dta("angrist_krueger.dta")
## Load data
data <- as.data.table(df)
data[, qob_1 := (qob == 1)]
View(data)
data[, qob_2 := (qob == 2)]
data[, qob_3 := (qob == 3)]
data[, qob_4 := (qob == 4)]
feols(
lwage ~ educ, # Regression formula
data,
vcov = "hc1" # ,r
)
binscatter <- binsreg(data$lwage, data$educ)
# plot and add labels
binscatter$bins_plot +
labs(y = "Log wages", x = "Years of Completed Schooling")
# Formula y ~ exogenous | fixed effects | endogenous ~ instrument
# 1 = constant, 0 = no fixed effects
feols(
lwage ~ 1 | 0 | educ ~ qob_1,
data,
vcov = "hc1"
)
data[,
.(n = .N, mean = mean(lwage), sd = sd(lwage), min = min(lwage), max = max(lwage)),
by = qob_1
]
data[,
.(n = .N, mean = mean(educ), sd = sd(educ), min = min(educ), max = max(educ)),
by = qob_1
]
(5.157450 - 5.148471) / (11.52515 - 11.39960 )
# collapse data by qob
collapsed <- data[,
.(lwage = mean(lwage), educ = mean(educ)),
by = qob
]
# plot means
plot(collapsed$educ, collapsed$lwage)
# add regression line
abline(feols(lwage ~ educ, collapsed))
feols(
lwage ~ 1 | yob | educ ~ qob_1,
data,
vcov = "hc1"
)
first_stage <- feols(educ ~ i(qob_1) | yob, data)
data[, educ_hat := predict(first_stage)]
feols(
lwage ~ educ_hat | yob,
data,
vcov = "hc1"
)
df <- haven::read_dta("hansen_dwi.dta")
