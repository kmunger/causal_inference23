simulations_c_state_mean = as.data.frame(aaply(laply(simulations_c_state, as.matrix), c(2, 3), mean))
simulations_c_pref_mean = as.data.frame(aaply(laply(simulations_c_pref, as.matrix), c(2, 3), mean))
simulations_p_pref_mean = as.data.frame(aaply(laply(simulations_p_pref, as.matrix), c(2, 3), mean))
## SEIR histogram
# histlong <- melt(disthist.df,id.vars="day")
# ggplot(histlong,aes(x=day,y=value,fill=variable)) + geom_bar(stat="identity",position="stack") +
#   theme_bw()
## SEIR plot:
plot1 <- ggplot(melt(simulations_c_state_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + theme_bw() + ggtitle(label="Social network model (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="States") #  + ylim(0,500)
png(file="seir_1.png", width=600, height=500)
plot1
dev.off()
## make consumer pref plot for N simulations:
plot_consumer_pref <- ggplot(melt(simulations_c_pref_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + ggtitle(label="Social network model-consumer preferences (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="Consumer Preferences") # + ylim(20,80)
png(file="consumer_pref_1.png", width=600, height=500)
plot_consumer_pref
dev.off()
## make producer pref plot for N simulations:
plot_producer_pref <- ggplot(melt(simulations_p_pref_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + ggtitle(label="Social network model-producer preferences (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="Producer Preferences") # + ylim(20,90)
png(file="producer_pref_1.png", width=600, height=500)
plot_producer_pref
dev.off()
#### Has the network plots code
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))
### Individual-Based Contact Models (ICMs) ###
# not deterministic compartmental model => we are using stochastic individual based models (IBM/ABM).
#### we are using limited stochastic model
### Hypothesis: addition of a small percentage of low digital-literacy users, who are unable to accurately vet information can dramatically increase the vulnerability of this ecosystem to manipulation by malign actors
library(ggplot2)
library(plyr)
library(dplyr)
library(sna)
library(knitr)
library(reshape2)
# Make news quality scale with the number of shares on the news item. The intuition that I'd love to capture is the credibility cascades idea; in particular, that there are some pieces of news content that *never* get shared if everyone is high DL, but adding some low DL ppl gets those items above the threshold, and they then cascade
###### 1) Create agents ####
### create global variables to define the model, including the labels for the states
Consumer_states <- 4
Consumer_state_names <- c("Ignorant", "Exposed" ,"Spreader", "Stifler")
Consumer_state_labels <- c("Ignorant", "Exposed" ,"Spreader", "Stifler")
makeAgent <- function(consumer, consumer_pref, producer_pref,
digital_literacy, producer_quality) # add literacy?
{
return(list(c_state = consumer,  # current consumer state
c_pref = consumer_pref,  # current producer state
p_pref = producer_pref,   # current producer content quality state
c_literacy = digital_literacy,  # digital
p_quality = producer_quality, # producer quality
next_c_state = NA,
c_state_countdown= NA))
}
###### 2) Create transition matrix ####
# * 1. Ignorant => who don't know the rumor; hear rumor => contemplate and seek confirmation before making decisions
# * 2. Exposed => who know the rumor but hesitate to believe it and dont spread it.
# * 3. Spreader => People who spread the rumor
# * 4. Stifler => know the rumor but never spread it or stop spreading it.
consTransition <- matrix(0,Consumer_states,Consumer_states)
consMin <- matrix(1,Consumer_states)      #state time minimum
consMax <- matrix(1,Consumer_states)      #state time maximum
consMin[,1] <- 1 #each state has 1 time.
consMax[,1] <- 1
# starting from steady ignorant. Note that these are just referring to
consTransition[1,2] <- 1.0 # transition to exposed from ignorant
consTransition[2,4] <- 0.5 # transition to stifler from exposed
consTransition[2,3] <- 0.5 # transition to spreader from exposed
consTransition[3,4] <- 1 # transition to stifler from spreader
# consTransition[3,3] <- 0.5 # transition to spreader from spreader
consTransition[4,1] <- 1 # transition to ignorant from stifler          ### switch to 1 if we want SEIRS model
# par(xpd=NA,mar=c(1,1,1,1))
# set.seed(44)
# gplot(consTransition,label=Consumer_state_labels, mode="kamadakawai", diag=T, vertex.col = "#48ac8c", edge.col = "gray28")
setAgentState <- function(agent, consumer, digital_literacy, producer_quality, producer_pref) {
agent$c_state <- consumer
# agent$c_pref <- consumer_pref
agent$c_literacy <- digital_literacy
agent$p_pref <- producer_pref
agent$p_quality <- producer_quality
if(sum(consTransition[consumer,])>0){
# Above line checks if there is possibility to move from the current state to something else.
agent$c_state_countdown <- sample(x=seq(consMin[consumer],consMax[consumer]),1)
# set time parameter (we specified min and max equal to 1; so agent can stay in each state only 1 iteration)
### Rule for state 1, 3 and 4. Simply move to next possible state
if ((agent$c_state == 1 || agent$c_state ==3 || agent$c_state ==4)) {
agent$next_c_state <- sample(1:Consumer_states, prob=consTransition[agent$c_state,],size=1)
}
### Rule for state 2 => either state 3 or state 4 based on credibility calculation
else if (agent$c_state == 2){
# Change the quality measure => quality shown to only high digital literacy users (make sure it doesn't bias => 3 to all of them or random drawn. Normal value shown to high digital literacy users) ... Interact the news quality w DL so that only high DL ppl can observe the signal of news quality. This could produce the "mistakes" that we tried to hardcode before #
if (agent$c_literacy > 0.8){ # if greater than 0.8 OR 0.5 (need to change); show producer quality
credibility <- 1-abs(agent$c_pref - agent$p_pref) + agent$p_quality
agent$next_c_state <- ifelse(credibility > 1.1, 3, 4)  # if credibility is greater than 0.5, move to 3 (spreader state).
# uncomment to add mistake/flip part
#agent$next_c_state <- ifelse(runif(1, min=0, max=1) > agent$c_literacy,
#                            ifelse(agent$next_c_state == 3, 4, 3), agent$next_c_state)  # if greater than the literacy score make a mistake and go to incorrect state
if (agent$next_c_state ==3) { # Update agents's preference 1 unit in the direction of the producer preference
# if it finds the item credible, change consumer preference 1 unit in that direction.
agent$c_pref2 <- ifelse(agent$p_pref > agent$c_pref,  agent$c_pref + .1, agent$c_pref - .1 )
agent$c_pref <- ifelse((agent$c_pref2 >= 0.9 | agent$c_pref2 <= 0), agent$p_pref, agent$c_pref2) # if both have same value, it can push the preference to 0 or 0.9 (min and max).
agent$c_pref2 <- NULL
} }
else{ # if literacy less than threshold, use 0.5 producer quality.
# credibility <- mean(c(1-abs(agent$c_pref - agent$p_pref),
#                       0.5))
credibility <- 1-abs(agent$c_pref - agent$p_pref) + 1
agent$next_c_state <- ifelse(credibility > 1.1, 3, 4)  # if credibility is greater than 0.5, move to 3 (spreader state). Update agents's preference 1 unit in the direction of the producer preference
# uncomment to add mistake/flip part
#agent$next_c_state <- ifelse(runif(1, min=0, max=1) > agent$c_literacy,
#                            ifelse(agent$next_c_state == 3, 4, 3), agent$next_c_state)  # if greater than the literacy score make a mistake and go to incorrect state
if (agent$next_c_state ==3) {
# if it finds the item credible, change consumer preference 1 unit in that direction.
agent$c_pref2 <- ifelse(agent$p_pref > agent$c_pref,  agent$c_pref + .1, agent$c_pref - .1 )
agent$c_pref <- ifelse((agent$c_pref2 >= 0.9 | agent$c_pref2 <= 0), agent$p_pref, agent$c_pref2) # if both have same value, it can push the preference to 0 or 0.9 (min and max).
agent$c_pref2 <- NULL
}
}
}
}
else{
agent$c_state_countdown <- NA
agent$next_c_state <- NA   ##just so we can tell if the agent is finished.
}
return(agent)
}
transitionAgent<- function(agent)
{
return(setAgentState(agent,agent$next_c_state, agent$c_literacy, agent$p_quality, agent$p_pref))
}
updateAgent<- function(agent)
{
if(!is.na(agent$c_state_countdown))
{
agent$c_state_countdown <- agent$c_state_countdown - 1
if(agent$c_state_countdown <=0)  ##new state
{
agent <- transitionAgent(agent)
}
}
return(agent)
}
###### 4) SNA component to the model (social network model) ####
#### Incorporating social network into the model ####
makeNetwork<- function(numAgents,numsets=2,steps=2,power=0.69)
{
ord <- sample(numAgents)
tmp<-igraph::as_adjacency_matrix(igraph::sample_pa(numAgents,power=power),sparse=F)
tmp <- tmp + t(tmp)
tmp <- tmp[ord,ord]
if(numsets>1)
{
for(i in 2:numsets)
{
ord <- sample(numAgents)
sn2 <-igraph::as_adjacency_matrix(igraph::sample_pa(numAgents,power=power),sparse=F)[ord,ord]
### use 'sample_smallworld()' for WS, 'sample_gnp()' or 'sample_gnm()' for ER
tmp <- tmp + sn2 + t(sn2)
}
}
if(steps>1)
{
for(i in 2:steps)
{
tmp <- tmp + tmp %*% tmp  ## iterate to neighbors
}
}
(tmp>0)+0
}
mygplot <- function(coord, network,states,main="")
{
if(is.null(coord))
{
coord  <- gplot.layout.fruchtermanreingold(network,layout.par=list(niter=1000))
}
newmin <- mean(coord[,2]) - (-min(coord[,2]) + mean(coord[,2])) * 1.4
palette=c("springgreen4","coral3","firebrick4","steelblue3")
plot(coord,col="black",bty="n",pch=16,cex=2.7,xaxt="n",yaxt="n",main=main,xlab="",ylab="",axes=F,
ylim=c(newmin,max(coord[,2])),type="n")
for(i in 1:nrow(network))
segments(coord[i,1],
coord[i,2],
coord[network[i,]==1,1],
coord[network[i,]==1,2],col="grey40")
points(coord,pch=16,cex=2.3,col= palette[states])
points(coord,pch=1,cex=2.3,col="black")
legend("bottom",bty='n',y.intersp=.7,cex=.8, horiz=TRUE,
Consumer_state_names, pch=16,col=palette)
return (coord)
}
set.seed(123)
socialnetwork <- makeNetwork(1000,numsets=2,power=.65,steps=2)
cc <-  mygplot(coord=NULL,socialnetwork,rep(1,nrow(socialnetwork)),main="Initial state")
#### Set 1: Two interactions; get rid of high quality condition. => uniform distribution ####
#### 4.1) Social network model - Everyone high DL x uniform distribution of producer preferences ####
simulations_mean_cp_df <- list()
simulations_c_state <- list()
simulations_c_pref <- list()
simulations_p_pref <- list()
simulation <- 10 # run 100 times
# set.seed(123)
for (j in 1:simulation){
set.seed(j)
numAgents <- 1000
# naturalImmunity <- .01  #1 % naturally immune
numInteractions <-  1 # how many interactions per day per agent on average?
numDays <- 50 # day is essentially iterations.
sampleFromNetwork <- 1 # 0.98 => 98% from the network. use only the network; dont allow for jumps
plotNetwork <-T
socialnetwork <-makeNetwork(numAgents,numsets=1,power=.65,steps=2)
if(plotNetwork)
{
cc <-mygplot(coord=NULL,socialnetwork,rep(1,nrow(socialnetwork)),main="Initial state")
}
consumer_state_history <- matrix(NA,ncol=Consumer_states,nrow=numDays+1)
consumer_pref_history <- matrix(NA,ncol=10,nrow=numDays+1)
producer_pref_history <- matrix(NA,ncol=10,nrow=numDays+1)
## create the pool of agents
pool <- list()
for(i in 1:numAgents)
{
pool[[i]] <- makeAgent(consumer = sample(1,size=1),
consumer_pref = sample(seq(0.1,.9,0.1), size=1), # uniform distribution of consumer preferences
producer_pref = sample(seq(0.1,.9,0.1), size=1), # uniform distribution of producer preferences
# digital_literacy = sample(c(0.2,0.4,0.6,0.8,1), size=1, prob = c(0.,0.,0.0,0.0,1.0)), # all high DL; higher means higher literacy
# producer_quality = sample(c(0.2,0.4,0.6,0.8,1), size=1)) # uniform distribution of high P_quality
digital_literacy = 1, # all high DL
producer_quality = 1) # all high quality
}
## infect the system
numInfected <-400 # create N infected agents
set.seed(j)
for(i in sample(numAgents,numInfected))
{
pool[[i]] <- setAgentState(pool[[i]], consumer = 1, digital_literacy = pool[[i]]$c_literacy,
producer_quality = pool[[i]]$p_quality, producer_pref = pool[[i]]$p_pref)
}
## subset the pool to those that are not initially set and calculate mean in consumer preferences
set.seed(j)
id_infected <- sample(numAgents, numInfected)
pool2 <- pool
for (i in id_infected){pool2[[i]] <- NA}
pool3 <- pool2[!(is.na(pool2))]
x <- NA
for ( i in 1:length(pool3)){x[i]<-pool3[[i]]$c_pref}
mean_cp <- matrix(NA, ncol=3, nrow=numDays+1,)
colnames(mean_cp) <- c("mean_simulation", "initial_mean", "iteration")
mean_cp.df <- as.data.frame(mean_cp)
mean_cp.df[,2] <- mean(x)
mean_cp.df[,3] <- 0:numDays
mean_cp.df[1,1] <- mean(x)
## create empty matrices to store values in loop
consumer_state_history[1,] <- table(factor(sapply(pool,FUN=function(x){x$c_state}),levels=1:4))
# consumer_pref_history[1,] <- table(factor(sapply(pool,FUN=function(x){x$c_pref}),levels=1:10))
# producer_pref_history[1,] <- table(factor(sapply(pool,FUN=function(x){x$p_pref}),levels=1:10))
consumer_pref_history[1,] <- table(factor(sapply(pool,FUN=function(x){x$c_pref}),levels=seq(0.1,1,0.1)))
producer_pref_history[1,] <- table(factor(sapply(pool,FUN=function(x){x$p_pref}),levels=seq(0.1,1,0.1)))
## spread within the system
for(day in 1:numDays)
{
##who are you going to talk to today.
sneezers <- rep(1:numAgents,each=numInteractions)
sneezedons <- rep(NA,length(sneezers))
for(i in 1:length(sneezers))
{
if(runif(1)<(1-sampleFromNetwork))
{
sneezedons[i] <- sample(numAgents,1)
}else{
sneezedons[i] <- sample(1:numAgents,prob=socialnetwork[sneezers[i],],1)
}
}
for(i in 1:length(sneezers))
{
agent1 <- pool[[ sneezers[i] ]]
agent2 <- pool[[ sneezedons[i] ]]
##this constitutes the rules of infection.
if((agent1$c_state==3) & (agent2$c_state=1) ) #& runif(1)<contagionProb) ### NB! problem here. We allow the interaction only if the second agent is in the 1st state. This makes sense, HOWEVER,there is a possibility that a spreader will inteact with a spreader.
{
pool[[ sneezedons[i] ]] <- setAgentState(agent2, consumer=2, digital_literacy = agent2$c_literacy, producer_quality = agent1$p_quality, producer_pref = agent1$p_pref ) ##infect!
}
}
## subset the pool to those that are not initially set and calculate mean in consumer preferences
pool2 <- pool
for (i in id_infected){pool2[[i]] <- NA}
pool3 <- pool2[!(is.na(pool2))]
x <- NA
for ( i in 1:length(pool3)){x[i]<-pool3[[i]]$c_pref}
mean_cp.df[day+1,1] <- mean(x)
distrib <- table(factor(sapply(pool,FUN=function(x){x$c_state}),levels=1:4))
# distrib2 <- table(factor(sapply(pool,FUN=function(x){x$c_pref}),levels=1:10))
# distrib3 <- table(factor(sapply(pool,FUN=function(x){x$p_pref}),levels=1:10))
distrib2 <- table(factor(sapply(pool,FUN=function(x){x$c_pref}),levels=seq(0.1,1,0.1)))
distrib3 <- table(factor(sapply(pool,FUN=function(x){x$p_pref}),levels=seq(0.1,1,0.1)))
consumer_state_history[day+1,] <- distrib
consumer_pref_history[day+1,] <- distrib2
producer_pref_history[day+1,] <- distrib3
##increment each agent 1-day.
for(i in 1:numAgents)
{
pool[[i]] <- updateAgent(pool[[i]])
}
# if(plotNetwork)
# {
#   mygplot(cc,socialnetwork,states,main=paste("Iteration",day))
# }
}
# mean absolute difference in consumer preferences over iterations
mean_cp.df$diff <- abs(mean_cp.df$initial_mean - mean_cp.df$mean_simulation)
mean_cp.df
# table of states over iterations
disthist.df <-as.data.frame(consumer_state_history)
colnames(disthist.df) <- Consumer_state_names
disthist.df$iteration <- c(1:nrow(disthist.df)-1)
# table of consumer preferences over iterations
consumer_pref_history.df <- as.data.frame(consumer_pref_history)
colnames(consumer_pref_history.df) <- 1:10
consumer_pref_history.df$iteration <- c(1:nrow(consumer_pref_history)-1)
# print(kable(consumer_pref_history.df))
# table of producer preferences over iterations
producer_pref_history.df <- as.data.frame(producer_pref_history)
colnames(producer_pref_history.df) <- 1:10
producer_pref_history.df$iteration <- c(1:nrow(producer_pref_history)-1)
# print(kable(producer_pref_history.df))
simulations_mean_cp_df[[j]] <- mean_cp.df
simulations_c_state[[j]] <- disthist.df
simulations_c_pref[[j]] <- consumer_pref_history.df
simulations_p_pref[[j]] <- producer_pref_history.df
}
# get the mean of the N simulations
simulations_mean_cp_df_mean_9 = as.data.frame(aaply(laply(simulations_mean_cp_df, as.matrix), c(2, 3), mean))
simulations_c_state_mean = as.data.frame(aaply(laply(simulations_c_state, as.matrix), c(2, 3), mean))
simulations_c_pref_mean = as.data.frame(aaply(laply(simulations_c_pref, as.matrix), c(2, 3), mean))
simulations_p_pref_mean = as.data.frame(aaply(laply(simulations_p_pref, as.matrix), c(2, 3), mean))
## SEIR histogram
# histlong <- melt(disthist.df,id.vars="day")
# ggplot(histlong,aes(x=day,y=value,fill=variable)) + geom_bar(stat="identity",position="stack") +
#   theme_bw()
## SEIR plot:
plot1 <- ggplot(melt(simulations_c_state_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + theme_bw() + ggtitle(label="Social network model (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="States") #  + ylim(0,500)
png(file="seir_1.png", width=600, height=500)
plot1
dev.off()
## make consumer pref plot for N simulations:
plot_consumer_pref <- ggplot(melt(simulations_c_pref_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + ggtitle(label="Social network model-consumer preferences (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="Consumer Preferences") # + ylim(20,80)
png(file="consumer_pref_1.png", width=600, height=500)
plot_consumer_pref
dev.off()
## make producer pref plot for N simulations:
plot_producer_pref <- ggplot(melt(simulations_p_pref_mean,id.vars="iteration"),aes(x=iteration,group=variable,y=value,color=variable)) + geom_line() + theme_bw() + ggtitle(label="Social network model-producer preferences (50 simulations)", subtitle="Everyone high DL x uniform distribution of producer preferences") + labs(x="Iteration", y="Count") + labs(color="Producer Preferences") # + ylim(20,90)
png(file="producer_pref_1.png", width=600, height=500)
plot_producer_pref
dev.off()
# change wd as needed:
setwd("C:/Users/Kevin/Documents/GitHub/causal_inference23/code/a_s2016")
library(maptools)
library(foreign)
world <-  readShapePoly("5603/world_countries_boundary_file_world_2002.shp")
install.packages("maptools")
install.packages("maptools")
library(maptools)
install.packages("rgeos")
library(maptools)
rm(list=ls())
library(maptools)
library(foreign)
world <-  readShapePoly("5603/world_countries_boundary_file_world_2002.shp")
world <-  readShapePoly("world_countries_boundary_file_world_2002.shp")
jensen.cc <- read.dta("jensen-rep.dta")
X.vars <- c(	"var5",
"market",
"lgdppc",
"gdpgrowt",
"tradeofg",
"overallb",
"generalg",
"country",
"d2",
"d3")
X.vars.f <- paste(X.vars,collapse="+")
fit.y <- lm(as.formula(paste("Fvar5~regime+", X.vars.f, sep="")), data=jensen.cc)
fit.d <- lm(as.formula(paste("regime~", X.vars.f, sep="")), data=jensen.cc)
d.tilde <- as.numeric(residuals(fit.d))
w <- d.tilde^2
w1 <- tapply(w, jensen.cc$country, mean)
mapnames <-  read.csv("mapnames_filled.csv")
mapnames$weight <- 0
mapnames$weight[match(rownames(w1), mapnames$jensen)] <- as.numeric(w1)
attributes(world)$data$weight <- 0
attributes(world)$data$weight[match(mapnames$mapname,attributes(world)$data$NAME)] <- mapnames$weight
attributes(world)$data$incl <- 0
attributes(world)$data$incl[match(mapnames$mapname,attributes(world)$data$NAME)] <- as.numeric(!is.na(mapnames$jensen))
pdf(file="jensen-nominal-map.pdf", height=5, width=8)
plot(	world,
col=gray(1-.75*attributes(world)$data$incl),
border="gray", lwd=.25)
dev.off()
pdf(file="jensen-effective-map.pdf", height=5, width=8)
plot(	world,
col=gray(1-abs(attributes(world)$data$weight)/max(abs(attributes(world)$data$weight))),
border="gray", lwd=.25)
dev.off()
rm(list=ls())
library(foreign)
library(xtable)
gerb <- read.dta("gerber-huber-analysis-data.dta")
fit <- lm(delta_vacationspend~pre_pid5
+C_age
+C_age2
+C_female
+C_hispanic
+C_black
+C_union
+C_income
+C_incomedkna
+C_educ, data=gerb)
vars.all <- attributes(gerb)$names
labs.all <- attributes(gerb)$var.labels
vars <- c("pre_pid5",
"C_age",
"C_female",
"C_hispanic",
"C_black",
"C_union",
"C_income",
"C_incomedkna",
"C_educ",
"pre_hhincomeforecast",
"post_hhincomeforecast",
"pre_nationaleconforecast",
"post_nationaleconforecast",
"delta_holidayspend",
"delta_vacationspend",
"pre_happy",
"post_happy",
"pre_stateeconforecast",
"post_stateeconforecast")
labs <- labs.all[match(vars, vars.all)]
# summary statistics
wt <- gerb$wt
meannum <- function(x) mean(as.numeric(x), na.rm=T)
sdnum <- function(x) (mean(as.numeric(x)^2, na.rm=T) - mean(as.numeric(x), na.rm=T)^2)^.5
wtmeannum <- function(x) weighted.mean(as.numeric(x),wt, na.rm=T)
wtmeannum2 <- function(x) weighted.mean(as.numeric(x),gerb$weight, na.rm=T)
wtsdnum <- function(x) (weighted.mean(as.numeric(x)^2,wt, na.rm=T) - weighted.mean(as.numeric(x),wt, na.rm=T)^2)^.5
minnum <- function(x) min(as.numeric(x), na.rm=T)
maxnum <- function(x) max(as.numeric(x), na.rm=T)
nomsampmean <- apply(gerb[,vars], 2, meannum)
nomsampsd <- apply(gerb[,vars], 2, sdnum)
effsampmean <- apply(gerb[,vars], 2, wtmeannum)
effsampsd <- apply(gerb[,vars], 2, wtsdnum)
sumstats <- round(100*cbind(nomsampmean,
nomsampsd,
effsampmean,
effsampsd))/100
rownames(sumstats) <- labs
colnames(sumstats) <- c("Mean",
"S.D.",
"Mean",
"S.D.")
xtable(sumstats)
world <-  readShapePoly("world_countries_boundary_file_world_2002.shp")
jensen.cc <- read.dta("jensen-rep.dta")
X.vars <- c(	"var5",
"market",
"lgdppc",
"gdpgrowt",
"tradeofg",
"overallb",
"generalg",
"country",
"d2",
"d3")
X.vars.f <- paste(X.vars,collapse="+")
fit.y <- lm(as.formula(paste("Fvar5~regime+", X.vars.f, sep="")), data=jensen.cc)
fit.d <- lm(as.formula(paste("regime~", X.vars.f, sep="")), data=jensen.cc)
summary(fit.y)
summary(fit.d)
d.tilde <- as.numeric(residuals(fit.d))
w <- d.tilde^2
w1 <- tapply(w, jensen.cc$country, mean)
mapnames <-  read.csv("mapnames_filled.csv")
mapnames$weight <- 0
mapnames$weight[match(rownames(w1), mapnames$jensen)] <- as.numeric(w1)
attributes(world)$data$weight <- 0
attributes(world)$data$weight[match(mapnames$mapname,attributes(world)$data$NAME)] <- mapnames$weight
attributes(world)$data$incl <- 0
attributes(world)$data$incl[match(mapnames$mapname,attributes(world)$data$NAME)] <- as.numeric(!is.na(mapnames$jensen))
plot(	world,
col=gray(1-.75*attributes(world)$data$incl),
border="gray", lwd=.25)
plot(	world,
col=gray(1-abs(attributes(world)$data$weight)/max(abs(attributes(world)$data$weight))),
border="gray", lwd=.25)
attributes(world)$data
attributes(world)$data$weight
sum(attributes(world)$data$weight)
sort(attributes(world)$data$weight, decreasing = T)
plot(sort(attributes(world)$data$weight, decreasing = T))
sum(w)
plot(sort(w, decreasing = T))
rm(list=ls())
library(foreign)
library(xtable)
gerb <- read.dta("gerber-huber-analysis-data.dta")
fit <- lm(delta_vacationspend~pre_pid5
+C_age
+C_age2
+C_female
+C_hispanic
+C_black
+C_union
+C_income
+C_incomedkna
+C_educ, data=gerb)
